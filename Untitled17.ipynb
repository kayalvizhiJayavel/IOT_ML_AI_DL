{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kayalvizhiJayavel/IoT/blob/master/Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yj5L3pjnWDS"
      },
      "source": [
        "Reference link: https://victorzhou.com/blog/keras-cnn-tutorial/\n",
        "\n",
        "https://ubajaka.medium.com/deep-learning-with-mnist-dataset-ddf2bcde0b8a\n",
        "\n",
        "https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjqladFBpU0O"
      },
      "source": [
        "# Why numpy: Helps to work with Arrays, Linear Algebra, Fourier Tansform and Matrices\n",
        "import numpy as np\n",
        "# Modern National Institute of Standards and Technology: Hadndwritten Digits Dataset\n",
        "from keras.datasets import mnist\n",
        "# Why Sequential Model: Suitable for stack of layers, with each layer having exactly one input tensor and one output tensor. \n",
        "# Not suitable for models with any of your layer havning multiple inputs or multiple outputs. \n",
        "from keras.models import Sequential\n",
        "# Dense layer is the regular deeply connected neural network layer. \n",
        "# It is most common and frequently used layer. \n",
        "# Dense layer does the below operation on the input and return the output.\n",
        "#output = activation(dot(input, kernel) + bias)\n",
        "from keras.layers import Dense\n",
        "# to_categorical\n",
        "# Converts a class vector (integers) to binary class matrix.\n",
        "# In other words array of class integers into an array of one-hot vectors instead. \n",
        "# For example, 2 would become [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] (it’s zero-indexed).\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCmf2ePbpdIr",
        "outputId": "1eb52a2c-c4ca-4d15-b4d1-c44a73a0d21a"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# Normalize the images.\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4WM452Qplrh"
      },
      "source": [
        "# Flatten the images.\n",
        "# Flatten is to compress and reduce size, \n",
        "# and this is achieved through merging visible layers on to the background layers, so as to reduce size \n",
        "# -1 indicates dynamic computation of batch size in such a way so that the shape reamins intact in every entry (say n, \n",
        "# if there are n elements and each element is a 28X28 image(784), then it is n*784)\n",
        "train_images = train_images.reshape((-1, 784))\n",
        "test_images = test_images.reshape((-1, 784))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7TB7mhqprWJ"
      },
      "source": [
        "# https://victorzhou.com/blog/softmax/\n",
        "model = Sequential([\n",
        " Dense(64, activation='relu', input_shape=(784,)),\n",
        " Dense(64, activation='relu'),\n",
        " Dense(10, activation='softmax'),\n",
        "])\n",
        "# Compile the model.\n",
        "model.compile(\n",
        " optimizer='adam',\n",
        " loss='categorical_crossentropy',\n",
        " metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km33haLlp9uJ",
        "outputId": "341dbe90-1e87-4581-996c-efac3cb6d9f8"
      },
      "source": [
        "#This doesn’t actually work yet, though - we overlooked one thing. \n",
        "#Keras expects the training targets to be 10-dimensional vectors, since there are 10 nodes in our Softmax output layer (Dense Function), \n",
        "#but we’re instead supplying a single integer representing the class for each image.\n",
        "#so this is reslved using utlity method to_categorical as already mentioned above.\n",
        "model.fit(\n",
        " train_images,\n",
        " to_categorical(train_labels),\n",
        " epochs=5,\n",
        " batch_size=32,\n",
        ")\n",
        "predictions = model.predict(test_images[:15])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5789 - accuracy: 0.8202\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2000 - accuracy: 0.9402\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1469 - accuracy: 0.9548\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1239 - accuracy: 0.9616\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1061 - accuracy: 0.9671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "454OqFONqaJK",
        "outputId": "bf3d2d73-45c7-4948-882e-161cee0b2d5e"
      },
      "source": [
        "# output layer has 10 classes and activation is softmax, so it will be in probablities, \n",
        "# but in order convert back to integer representation we use argmax()\n",
        "print(\"predicted   :{}\".format(np.argmax(predictions, axis=1))) # [7, 2, 1, 0, 4]\n",
        "# ground truths.\n",
        "print(\"test inputs :{}\".format(test_labels[:15])) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted   :[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1]\n",
            "test inputs :[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}